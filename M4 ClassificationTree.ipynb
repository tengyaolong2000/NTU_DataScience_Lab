{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Tree in Python\n",
    "\n",
    "Dataset from Kaggle : **\"Pokemon with stats\"** by *Alberto Barradas*  \n",
    "Source: https://www.kaggle.com/abcsds/pokemon (requires login)\n",
    "\n",
    "---\n",
    "\n",
    "### Essential Libraries\n",
    "\n",
    "Let us begin by importing the essential Python Libraries.\n",
    "\n",
    "> NumPy : Library for Numeric Computations in Python  \n",
    "> Pandas : Library for Data Acquisition and Preparation  \n",
    "> Matplotlib : Low-level library for Data Visualization  \n",
    "> Seaborn : Higher-level library for Data Visualization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set() # set the default Seaborn style for graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Import the Dataset\n",
    "\n",
    "The dataset is in CSV format; hence we use the `read_csv` function from Pandas.  \n",
    "Immediately after importing, take a quick look at the data using the `head` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                   Name Type 1  Type 2  Total  HP  Attack  Defense  \\\n",
       "0  1              Bulbasaur  Grass  Poison    318  45      49       49   \n",
       "1  2                Ivysaur  Grass  Poison    405  60      62       63   \n",
       "2  3               Venusaur  Grass  Poison    525  80      82       83   \n",
       "3  3  VenusaurMega Venusaur  Grass  Poison    625  80     100      123   \n",
       "4  4             Charmander   Fire     NaN    309  39      52       43   \n",
       "\n",
       "   Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0       65       65     45           1      False  \n",
       "1       80       80     60           1      False  \n",
       "2      100      100     80           1      False  \n",
       "3      122      120     80           1      False  \n",
       "4       60       50     65           1      False  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkmndata = pd.read_csv('pokemonData.csv')\n",
    "pkmndata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of the dataset, as available on Kaggle, is as follows.\n",
    "Learn more : https://en.wikipedia.org/wiki/List_of_Pok%C3%A9mon\n",
    "\n",
    "> **\\#** : ID for each Pokemon (runs from 1 to 721)  \n",
    "> **Name** : Name of each Pokemon  \n",
    "> **Type 1** : Each Pokemon has a basic Type, this determines weakness/resistance to attacks  \n",
    "> **Type 2** : Some Pokemons are dual type and have a Type 2 value (set to nan otherwise)  \n",
    "> **Total** : Sum of all stats of a Pokemon, a general guide to how strong a Pokemon is  \n",
    "> **HP** : Hit Points, defines how much damage a Pokemon can withstand before fainting  \n",
    "> **Attack** : The base modifier for normal attacks by the Pokemon (e.g., scratch, punch etc.)  \n",
    "> **Defense** : The base damage resistance of the Pokemon against normal attacks  \n",
    "> **SP Atk** : Special Attack, the base modifier for special attacks (e.g. fire blast, bubble beam)  \n",
    "> **SP Def** : Special Defense, the base damage resistance against special attacks  \n",
    "> **Speed** : Determines which Pokemon attacks first each round  \n",
    "> **Generation** : Each Pokemon belongs to a certain Generation  \n",
    "> **Legendary** : Legendary Pokemons are powerful, rare, and hard to catch\n",
    "\n",
    "---\n",
    "\n",
    "Check the vital statistics of the dataset using the `type` and `shape` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type :  <class 'pandas.core.frame.DataFrame'>\n",
      "Data dims :  (800, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data type : \", type(pkmndata))\n",
    "print(\"Data dims : \", pkmndata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the variables (and their types) in the dataset using the `dtypes` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#              int64\n",
      "Name          object\n",
      "Type 1        object\n",
      "Type 2        object\n",
      "Total          int64\n",
      "HP             int64\n",
      "Attack         int64\n",
      "Defense        int64\n",
      "Sp. Atk        int64\n",
      "Sp. Def        int64\n",
      "Speed          int64\n",
      "Generation     int64\n",
      "Legendary       bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(pkmndata.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Simple Decision Tree\n",
    "\n",
    "We will start by setting up a simple Classification Problem.   \n",
    "\n",
    "Response Variable : **Legendary**     \n",
    "Predictor Feature : **Total**    \n",
    "\n",
    "Extract the variables and the associated data as a Pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "legnd = pd.DataFrame(pkmndata['Legendary'])  # Response\n",
    "total = pd.DataFrame(pkmndata['Total'])      # Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the classification problem with Train and Test datasets.   \n",
    "Train Set with 600 samples and Test Set with 200 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set : (600, 1) (600, 1)\n",
      "Test Set  : (200, 1) (200, 1)\n"
     ]
    }
   ],
   "source": [
    "# Train Set : 600 samples\n",
    "total_train = pd.DataFrame(total[:600])\n",
    "legnd_train = pd.DataFrame(legnd[:600])\n",
    "\n",
    "# Test Set : 200 samples\n",
    "total_test = pd.DataFrame(total[-200:])\n",
    "legnd_test = pd.DataFrame(legnd[-200:])\n",
    "\n",
    "# Check the sample sizes\n",
    "print(\"Train Set :\", legnd_train.shape, total_train.shape)\n",
    "print(\"Test Set  :\", legnd_test.shape, total_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(legnd_train[\"Legendary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Exploration\n",
    "\n",
    "Perform basic statistical exploration and visualization on the Train Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    557\n",
       "True      43\n",
       "Name: Legendary, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary Statistics for Legendary Train\n",
    "legnd_train[\"Legendary\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>432.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>122.365283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>325.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>515.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>780.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Total\n",
       "count  600.000000\n",
       "mean   432.715000\n",
       "std    122.365283\n",
       "min    180.000000\n",
       "25%    325.000000\n",
       "50%    440.000000\n",
       "75%    515.000000\n",
       "max    780.000000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary Statistics for Total Train\n",
    "total_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f95f23aa3a0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count Plot for Legendary Train\n",
    "sb.catplot(y = \"Legendary\", data = legnd_train, kind = \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the distributions of Total Train\n",
    "f, axes = plt.subplots(1, 3, figsize=(24, 6))\n",
    "sb.boxplot(data = total_train, orient = \"h\", ax = axes[0])\n",
    "sb.histplot(data = total_train, ax = axes[1])\n",
    "sb.violinplot(data = total_train, orient = \"h\", ax = axes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Total', ylabel='Legendary'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a joint dataframe by concatenating Total and Legendary\n",
    "trainDF = pd.concat([total_train, legnd_train], axis = 1).reindex(total_train.index)\n",
    "\n",
    "# Joint Boxplot of Total Train against Legendary Train\n",
    "f = plt.figure(figsize=(18, 6))\n",
    "sb.boxplot(x = \"Total\", y = \"Legendary\", data = trainDF, orient = \"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Total', ylabel='Legendary'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a joint dataframe by concatenating Total and Legendary\n",
    "trainDF = pd.concat([total_train, legnd_train], axis = 1).reindex(total_train.index)\n",
    "\n",
    "# Joint Swarmplot of Total Train against Legendary Train\n",
    "f = plt.figure(figsize=(18, 6))\n",
    "sb.swarmplot(x = \"Total\", y = \"Legendary\", data = trainDF, orient = \"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree in Scikit-Learn\n",
    "\n",
    "Scikit-Learn (`sklearn`) will be our de-facto Machine Learning library in Python.   \n",
    "Import the `DecisionTreeClassifier` model from `sklearn.tree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Decision Tree Classifier model from Scikit-Learn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create a Decision Tree Classifier object\n",
    "dectree = DecisionTreeClassifier(max_depth = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Decision Tree Classifier model `dectree` using the Train Set.   \n",
    "Use `total_train` as *Predictor* and `legnd_train` as *Response*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Decision Tree Classifier model\n",
    "dectree.fit(total_train, legnd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(372.0, 770.0, 'Total <= 579.5\\ngini = 0.133\\nsamples = 600\\nvalue = [557, 43]\\nclass = Ordinary'),\n",
       " Text(186.0, 462.0, 'gini = 0.0\\nsamples = 516\\nvalue = [516, 0]\\nclass = Ordinary'),\n",
       " Text(558.0, 462.0, 'Total <= 655.0\\ngini = 0.5\\nsamples = 84\\nvalue = [41, 43]\\nclass = Legendary'),\n",
       " Text(372.0, 154.0, 'gini = 0.48\\nsamples = 60\\nvalue = [36, 24]\\nclass = Ordinary'),\n",
       " Text(744.0, 154.0, 'gini = 0.33\\nsamples = 24\\nvalue = [5, 19]\\nclass = Legendary')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the trained Decision Tree\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "f = plt.figure(figsize=(12,12))\n",
    "plot_tree(dectree, filled=True, rounded=True, \n",
    "          feature_names=[\"Total\"], \n",
    "          class_names=[\"Ordinary\",\"Legendary\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goodness of Fit of the Model\n",
    "\n",
    "Check how good the predictions are on the Train Set.    \n",
    "Metrics : Classification Accuracy and Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy \t: 0.9516666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Legendary corresponding to Total Train\n",
    "legnd_train_pred = dectree.predict(total_train)\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(total_train, legnd_train))\n",
    "\n",
    "# Plot the two-way Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sb.heatmap(confusion_matrix(legnd_train, legnd_train_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how good the predictions are on the Test Set.    \n",
    "Metrics : Classification Accuracy and Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy \t: 0.935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Legendary corresponding to Total Test\n",
    "legnd_test_pred = dectree.predict(total_test)\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(total_test, legnd_test))\n",
    "\n",
    "# Plot the two-way Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sb.heatmap(confusion_matrix(legnd_test, legnd_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Tree with Random Train-Test Split\n",
    "\n",
    "Split the Train and Test sets randomly, and perform Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodness of Fit of Model \tTrain Dataset\n",
      "Classification Accuracy \t: 0.9483333333333334\n",
      "\n",
      "Goodness of Fit of Model \tTest Dataset\n",
      "Classification Accuracy \t: 0.945\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Recall the Legendary-Total Dataset\n",
    "legnd = pd.DataFrame(pkmndata['Legendary'])   # Response\n",
    "total = pd.DataFrame(pkmndata['Total'])       # Predictor\n",
    "\n",
    "# Split the Legendary-Total Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(total, legnd, test_size = 0.25)\n",
    "\n",
    "# Decision Tree using Train Data\n",
    "dectree = DecisionTreeClassifier(max_depth = 2)  # create the decision tree object\n",
    "dectree.fit(X_train, y_train)                    # train the decision tree model\n",
    "\n",
    "# Predict Legendary values corresponding to Total\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "y_test_pred = dectree.predict(X_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(372.0, 770.0, 'Total <= 579.5\\ngini = 0.153\\nsamples = 600\\nvalue = [550, 50]\\nclass = Ordinary'),\n",
       " Text(186.0, 462.0, 'gini = 0.0\\nsamples = 517\\nvalue = [517, 0]\\nclass = Ordinary'),\n",
       " Text(558.0, 462.0, 'Total <= 650.0\\ngini = 0.479\\nsamples = 83\\nvalue = [33, 50]\\nclass = Legendary'),\n",
       " Text(372.0, 154.0, 'gini = 0.499\\nsamples = 58\\nvalue = [30, 28]\\nclass = Ordinary'),\n",
       " Text(744.0, 154.0, 'gini = 0.211\\nsamples = 25\\nvalue = [3, 22]\\nclass = Legendary')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the trained Decision Tree\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "f = plt.figure(figsize=(12,12))\n",
    "plot_tree(dectree, filled=True, rounded=True, \n",
    "          feature_names=[\"Total\"], \n",
    "          class_names=[\"Ordinary\",\"Legendary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Multi-Variate Classification Tree\n",
    "\n",
    "We will start by setting up a Multi-Variate Classification problem.   \n",
    "\n",
    "Response Variable : **Legendary**     \n",
    "Predictor Feature : **Total, HP, Attack, Defense**       \n",
    "\n",
    "Extract the variables and the associated data as a Pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(pkmndata[\"Legendary\"])\n",
    "X = pd.DataFrame(pkmndata[[\"Total\", \"HP\", \"Attack\", \"Defense\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the classification problem with Train and Test datasets.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set : (600, 1) (600, 4)\n",
      "Test Set  : (200, 1) (200, 4)\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# Check the sample sizes\n",
    "print(\"Train Set :\", y_train.shape, X_train.shape)\n",
    "print(\"Test Set  :\", y_test.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Exploration\n",
    "\n",
    "Perform basic statistical exploration and visualization on the Train Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    551\n",
       "True      49\n",
       "Name: Legendary, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary Statistics for Response\n",
    "y_train[\"Legendary\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>435.986667</td>\n",
       "      <td>69.281667</td>\n",
       "      <td>79.256667</td>\n",
       "      <td>73.893333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.419647</td>\n",
       "      <td>26.293432</td>\n",
       "      <td>32.767519</td>\n",
       "      <td>31.596453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>330.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>450.000000</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>515.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>780.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>230.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Total          HP      Attack     Defense\n",
       "count  600.000000  600.000000  600.000000  600.000000\n",
       "mean   435.986667   69.281667   79.256667   73.893333\n",
       "std    120.419647   26.293432   32.767519   31.596453\n",
       "min    180.000000    1.000000    5.000000    5.000000\n",
       "25%    330.000000   50.000000   55.000000   50.000000\n",
       "50%    450.000000   65.500000   75.000000   70.000000\n",
       "75%    515.000000   80.000000  100.000000   90.000000\n",
       "max    780.000000  255.000000  190.000000  230.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary Statistics for Predictors\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f960196d8b0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draw the distribution of Response\n",
    "sb.catplot(y = \"Legendary\", data = legnd_train, kind = \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the distributions of all Predictors\n",
    "f, axes = plt.subplots(4, 3, figsize=(18, 16))\n",
    "\n",
    "count = 0\n",
    "for var in X_train:\n",
    "    sb.boxplot(data = X_train[var], orient = \"h\", ax = axes[count,0])\n",
    "    sb.histplot(data = X_train[var], ax = axes[count,1])\n",
    "    sb.violinplot(data = X_train[var], orient = \"h\", ax = axes[count,2])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tengyaolong/opt/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py:1296: UserWarning: 22.7% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/tengyaolong/opt/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py:1296: UserWarning: 10.9% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Relationship between Response and the Predictors\n",
    "trainDF = pd.concat([y_train, X_train], axis = 1).reindex(y_train.index)\n",
    "\n",
    "f, axes = plt.subplots(4, 1, figsize=(18, 24))\n",
    "\n",
    "count = 0\n",
    "for var in X_train:\n",
    "    sb.swarmplot(x = var, y = \"Legendary\", data = trainDF, orient = \"h\", ax = axes[count])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Tree in Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import DecisionTreeClassifier model from Scikit-Learn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Decision Tree using Train Data\n",
    "dectree = DecisionTreeClassifier(max_depth = 2)  # create the decision tree object\n",
    "dectree.fit(X_train, y_train)                    # train the decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(372.0, 770.0, 'Total <= 577.5\\ngini = 0.15\\nsamples = 600\\nvalue = [551, 49]\\nclass = Ordinary'),\n",
       " Text(186.0, 462.0, 'gini = 0.0\\nsamples = 514\\nvalue = [514, 0]\\nclass = Ordinary'),\n",
       " Text(558.0, 462.0, 'Total <= 650.0\\ngini = 0.49\\nsamples = 86\\nvalue = [37, 49]\\nclass = Legendary'),\n",
       " Text(372.0, 154.0, 'gini = 0.491\\nsamples = 60\\nvalue = [34, 26]\\nclass = Ordinary'),\n",
       " Text(744.0, 154.0, 'gini = 0.204\\nsamples = 26\\nvalue = [3, 23]\\nclass = Legendary')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the trained Decision Tree\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "f = plt.figure(figsize=(12,12))\n",
    "plot_tree(dectree, filled=True, rounded=True, \n",
    "          feature_names=X_train.columns, \n",
    "          class_names=[\"Ordinary\",\"Legendary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goodness of Fit of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodness of Fit of Model \tTrain Dataset\n",
      "Classification Accuracy \t: 0.9516666666666667\n",
      "\n",
      "Goodness of Fit of Model \tTest Dataset\n",
      "Classification Accuracy \t: 0.935\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Legendary values corresponding to Total\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "y_test_pred = dectree.predict(X_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Multi-Variate Classification Tree\n",
    "\n",
    "Let us set up another Multi-Variate Classification problem.   \n",
    "\n",
    "Response Variable : **Legendary**     \n",
    "Predictor Feature : **Total, HP, Attack, Defense, Sp. Atk, Sp. Def, Speed**       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodness of Fit of Model \tTrain Dataset\n",
      "Classification Accuracy \t: 0.9483333333333334\n",
      "\n",
      "Goodness of Fit of Model \tTest Dataset\n",
      "Classification Accuracy \t: 0.945\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(pkmndata['Legendary'])\n",
    "X = pd.DataFrame(pkmndata[[\"Total\", \"HP\", \"Attack\", \"Defense\", \"Sp. Atk\", \"Sp. Def\", \"Speed\"]]) \n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# Decision Tree using Train Data\n",
    "dectree = DecisionTreeClassifier(max_depth = 2)  # create the decision tree object\n",
    "dectree.fit(X_train, y_train)                    # train the decision tree model\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "y_test_pred = dectree.predict(X_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(372.0, 770.0, 'Total <= 579.5\\ngini = 0.147\\nsamples = 600\\nvalue = [552, 48]\\nclass = Ordinary'),\n",
       " Text(186.0, 462.0, 'gini = 0.0\\nsamples = 515\\nvalue = [515, 0]\\nclass = Ordinary'),\n",
       " Text(558.0, 462.0, 'Total <= 650.0\\ngini = 0.492\\nsamples = 85\\nvalue = [37, 48]\\nclass = Legendary'),\n",
       " Text(372.0, 154.0, 'gini = 0.495\\nsamples = 58\\nvalue = [32, 26]\\nclass = Ordinary'),\n",
       " Text(744.0, 154.0, 'gini = 0.302\\nsamples = 27\\nvalue = [5, 22]\\nclass = Legendary')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the trained Decision Tree\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "f = plt.figure(figsize=(12,12))\n",
    "plot_tree(dectree, filled=True, rounded=True, \n",
    "          feature_names=X_train.columns, \n",
    "          class_names=[\"Ordinary\",\"Legendary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Prediction using a Classification Tree\n",
    "\n",
    "Once we have trained a Multi-Variate Classification Tree, we may use it to predict **Legendary** for any particular Pokemon.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodness of Fit of Model \tTrain Dataset\n",
      "Classification Accuracy \t: 0.9616666666666667\n",
      "\n",
      "Goodness of Fit of Model \tTest Dataset\n",
      "Classification Accuracy \t: 0.945\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Extract Response and Predictors\n",
    "predictors = [\"Total\", \"HP\", \"Attack\", \"Defense\", \"Sp. Atk\", \"Sp. Def\", \"Speed\"]\n",
    "\n",
    "y = pd.DataFrame(pkmndata['Legendary'])\n",
    "X = pd.DataFrame(pkmndata[predictors]) \n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# Decision Tree using Train Data\n",
    "dectree = DecisionTreeClassifier(max_depth = 3)  # create the decision tree object\n",
    "dectree.fit(X_train, y_train)                    # train the decision tree model\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "y_test_pred = dectree.predict(X_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(348.75, 808.5, 'Total <= 579.5\\ngini = 0.147\\nsamples = 600\\nvalue = [552, 48]\\nclass = Ordinary'),\n",
       " Text(232.5, 577.5, 'gini = 0.0\\nsamples = 517\\nvalue = [517, 0]\\nclass = Ordinary'),\n",
       " Text(465.0, 577.5, 'Sp. Atk <= 71.0\\ngini = 0.488\\nsamples = 83\\nvalue = [35, 48]\\nclass = Legendary'),\n",
       " Text(232.5, 346.5, 'Attack <= 112.5\\ngini = 0.198\\nsamples = 9\\nvalue = [8, 1]\\nclass = Ordinary'),\n",
       " Text(116.25, 115.5, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]\\nclass = Legendary'),\n",
       " Text(348.75, 115.5, 'gini = 0.0\\nsamples = 8\\nvalue = [8, 0]\\nclass = Ordinary'),\n",
       " Text(697.5, 346.5, 'Attack <= 73.5\\ngini = 0.463\\nsamples = 74\\nvalue = [27, 47]\\nclass = Legendary'),\n",
       " Text(581.25, 115.5, 'gini = 0.278\\nsamples = 6\\nvalue = [5, 1]\\nclass = Ordinary'),\n",
       " Text(813.75, 115.5, 'gini = 0.438\\nsamples = 68\\nvalue = [22, 46]\\nclass = Legendary')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the trained Decision Tree\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "f = plt.figure(figsize=(12,12))\n",
    "plot_tree(dectree, filled=True, rounded=True, \n",
    "          feature_names=X_train.columns, \n",
    "          class_names=[\"Ordinary\",\"Legendary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction of Legendary\n",
    "\n",
    "Let's predict the value of **Legendary** for a few specific Pokemons -- *Mewtwo*, *Giratina* and *Butterfree* -- using the Classification Tree derived above.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12</td>\n",
       "      <td>Butterfree</td>\n",
       "      <td>Bug</td>\n",
       "      <td>Flying</td>\n",
       "      <td>395</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>150</td>\n",
       "      <td>Mewtwo</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>680</td>\n",
       "      <td>106</td>\n",
       "      <td>110</td>\n",
       "      <td>90</td>\n",
       "      <td>154</td>\n",
       "      <td>90</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>487</td>\n",
       "      <td>GiratinaOrigin Forme</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>680</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                  Name   Type 1  Type 2  Total   HP  Attack  Defense  \\\n",
       "15    12            Butterfree      Bug  Flying    395   60      45       50   \n",
       "162  150                Mewtwo  Psychic     NaN    680  106     110       90   \n",
       "545  487  GiratinaOrigin Forme    Ghost  Dragon    680  150     120      100   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "15        90       80     70           1      False  \n",
       "162      154       90    130           1       True  \n",
       "545      120      100     90           4       True  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Pokemons for Prediction\n",
    "pkmndata_pred = pkmndata[pkmndata[\"Name\"].isin([\"Mewtwo\", \"GiratinaOrigin Forme\", \"Butterfree\"])]\n",
    "pkmndata_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Predictors for Prediction\n",
    "X_pred = pd.DataFrame(pkmndata_pred[predictors])\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_pred = dectree.predict(X_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Legendary</th>\n",
       "      <th>PredLegend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Butterfree</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Mewtwo</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>GiratinaOrigin Forme</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name  Legendary  PredLegend\n",
       "15             Butterfree      False       False\n",
       "162                Mewtwo       True        True\n",
       "545  GiratinaOrigin Forme       True        True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize the Actuals and Predictions\n",
    "y_pred = pd.DataFrame(y_pred, columns = [\"PredLegend\"], index = pkmndata_pred.index)\n",
    "pkmndata_acc = pd.concat([pkmndata_pred[[\"Name\", \"Legendary\"]], y_pred], axis = 1)\n",
    "\n",
    "pkmndata_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction of Class Probabilities\n",
    "\n",
    "In case of any Classification Model, we should check the Class Probabilities along with the final Class Predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        ],\n",
       "       [0.32352941, 0.67647059],\n",
       "       [0.32352941, 0.67647059]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Probabilities corresponding to Predictors\n",
    "y_prob = dectree.predict_proba(X_pred)\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Legendary</th>\n",
       "      <th>PredLegend</th>\n",
       "      <th>ProbLegend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Butterfree</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Mewtwo</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>GiratinaOrigin Forme</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name  Legendary  PredLegend  ProbLegend\n",
       "15             Butterfree      False       False    0.000000\n",
       "162                Mewtwo       True        True    0.676471\n",
       "545  GiratinaOrigin Forme       True        True    0.676471"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize the Probabilities with the Predictions\n",
    "y_prob = pd.DataFrame(list(y_prob[:,1]), columns = [\"ProbLegend\"], index = pkmndata_pred.index)\n",
    "pkmndata_conf = pd.concat([pkmndata_acc, y_prob], axis = 1)\n",
    "\n",
    "pkmndata_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(348.75, 808.5, 'Total <= 579.5\\ngini = 0.147\\nsamples = 600\\nvalue = [552, 48]\\nclass = Ordinary'),\n",
       " Text(232.5, 577.5, 'gini = 0.0\\nsamples = 517\\nvalue = [517, 0]\\nclass = Ordinary'),\n",
       " Text(465.0, 577.5, 'Sp. Atk <= 71.0\\ngini = 0.488\\nsamples = 83\\nvalue = [35, 48]\\nclass = Legendary'),\n",
       " Text(232.5, 346.5, 'Attack <= 112.5\\ngini = 0.198\\nsamples = 9\\nvalue = [8, 1]\\nclass = Ordinary'),\n",
       " Text(116.25, 115.5, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]\\nclass = Legendary'),\n",
       " Text(348.75, 115.5, 'gini = 0.0\\nsamples = 8\\nvalue = [8, 0]\\nclass = Ordinary'),\n",
       " Text(697.5, 346.5, 'Attack <= 73.5\\ngini = 0.463\\nsamples = 74\\nvalue = [27, 47]\\nclass = Legendary'),\n",
       " Text(581.25, 115.5, 'gini = 0.278\\nsamples = 6\\nvalue = [5, 1]\\nclass = Ordinary'),\n",
       " Text(813.75, 115.5, 'gini = 0.438\\nsamples = 68\\nvalue = [22, 46]\\nclass = Legendary')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the trained Decision Tree\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "f = plt.figure(figsize=(12,12))\n",
    "plot_tree(dectree, filled=True, rounded=True, \n",
    "          feature_names=X_train.columns, \n",
    "          class_names=[\"Ordinary\",\"Legendary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Multi-Class Classification Tree\n",
    "\n",
    "Let us set up a Multi-Class Classification problem.   \n",
    "\n",
    "Response Variable : **Type 1**     \n",
    "Predictor Feature : **Total, HP, Attack, Defense, Sp. Atk, Sp. Def, Speed**       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Extract Response and Predictors\n",
    "predictors = [\"Total\", \"HP\", \"Attack\", \"Defense\", \"Sp. Atk\", \"Sp. Def\", \"Speed\"]\n",
    "\n",
    "y = pd.DataFrame(pkmndata['Type 1'].astype('category'))\n",
    "X = pd.DataFrame(pkmndata[predictors]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f95f1c95fa0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# Draw the distribution of Response\n",
    "sb.catplot(y = \"Type 1\", data = y_train, kind = \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between Response and the Predictors\n",
    "trainDF = pd.concat([y_train, X_train], axis = 1).reindex(y_train.index)\n",
    "\n",
    "f, axes = plt.subplots(7, 1, figsize=(18, 42))\n",
    "\n",
    "count = 0\n",
    "for var in X_train:\n",
    "    sb.boxplot(x = var, y = \"Type 1\", data = trainDF, orient = \"h\", ax = axes[count])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree using Train Data\n",
    "dectree = DecisionTreeClassifier(max_depth = 4)  # create the decision tree object\n",
    "dectree.fit(X_train, y_train)                    # train the decision tree model\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "y_test_pred = dectree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodness of Fit of Model \tTrain Dataset\n",
      "Classification Accuracy \t: 0.25833333333333336\n",
      "\n",
      "Goodness of Fit of Model \tTest Dataset\n",
      "Classification Accuracy \t: 0.2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(2, 1, figsize=(12, 24))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction of Type 1\n",
    "\n",
    "Let's predict the value of **Type 1** for a few specific Pokemons -- *Mewtwo*, *Giratina* and *Butterfree* -- using the Classification Tree derived above.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12</td>\n",
       "      <td>Butterfree</td>\n",
       "      <td>Bug</td>\n",
       "      <td>Flying</td>\n",
       "      <td>395</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>150</td>\n",
       "      <td>Mewtwo</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>680</td>\n",
       "      <td>106</td>\n",
       "      <td>110</td>\n",
       "      <td>90</td>\n",
       "      <td>154</td>\n",
       "      <td>90</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>487</td>\n",
       "      <td>GiratinaOrigin Forme</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>680</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                  Name   Type 1  Type 2  Total   HP  Attack  Defense  \\\n",
       "15    12            Butterfree      Bug  Flying    395   60      45       50   \n",
       "162  150                Mewtwo  Psychic     NaN    680  106     110       90   \n",
       "545  487  GiratinaOrigin Forme    Ghost  Dragon    680  150     120      100   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "15        90       80     70           1      False  \n",
       "162      154       90    130           1       True  \n",
       "545      120      100     90           4       True  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Pokemons for Prediction\n",
    "pkmndata_pred = pkmndata[pkmndata[\"Name\"].isin([\"Mewtwo\", \"GiratinaOrigin Forme\", \"Butterfree\"])]\n",
    "pkmndata_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Psychic', 'Dragon', 'Dragon'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Predictors for Prediction\n",
    "X_pred = pd.DataFrame(pkmndata_pred[predictors])\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_pred = dectree.predict(X_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>PredType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Butterfree</td>\n",
       "      <td>Bug</td>\n",
       "      <td>Psychic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Mewtwo</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Dragon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>GiratinaOrigin Forme</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>Dragon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name   Type 1 PredType\n",
       "15             Butterfree      Bug  Psychic\n",
       "162                Mewtwo  Psychic   Dragon\n",
       "545  GiratinaOrigin Forme    Ghost   Dragon"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize the Actuals and Predictions\n",
    "y_pred = pd.DataFrame(y_pred, columns = [\"PredType\"], index = pkmndata_pred.index)\n",
    "pkmndata_acc = pd.concat([pkmndata_pred[[\"Name\", \"Type 1\"]], y_pred], axis = 1)\n",
    "\n",
    "pkmndata_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction of Class Probabilities\n",
    "\n",
    "In case of any Classification Model, we should check the Class Probabilities along with the final Class Predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.    0.    0.07  0.093 0.    0.07  0.    0.07  0.14  0.    0.07\n",
      "  0.047 0.    0.256 0.07  0.    0.116]\n",
      " [0.021 0.042 0.25  0.021 0.021 0.021 0.104 0.    0.021 0.062 0.062 0.\n",
      "  0.062 0.    0.083 0.062 0.062 0.104]\n",
      " [0.021 0.042 0.25  0.021 0.021 0.021 0.104 0.    0.021 0.062 0.062 0.\n",
      "  0.062 0.    0.083 0.062 0.062 0.104]]\n"
     ]
    }
   ],
   "source": [
    "# Predict Probabilities corresponding to Predictors\n",
    "y_prob = dectree.predict_proba(X_pred)\n",
    "np.set_printoptions(precision = 3)\n",
    "print(y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
